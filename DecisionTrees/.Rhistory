wbcd_test_z <- wbcd_z[470:569, ]
#extraction of true labels for training and test results
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]
#run the KNN algo with k = 21 (sqrt(469)) with normalized data
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k = 21)
#run the KNN algo with k = 21 (sqrt(469)) with z-normalized data
wbcd_test_pred_z <- knn(train = wbcd_train_z, test = wbcd_test_z, cl = wbcd_train_labels, k = 21)
#compare results for both n and z normalized data
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq = FALSE)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred_z, prop.chisq = FALSE)
#import dataset
wbcd <- read.csv(url("https://raw.githubusercontent.com/dataspelunking/MLwR/master/Machine%20Learning%20with%20R%20(2nd%20Ed.)/Chapter%2003/wisc_bc_data.csv"))
#dataset info
str(wbcd)
#remove the unique "ID" feature for the observations (not a meaningful feature)
wbcd <- wbcd[-1]
table(wbcd$diagnosis)
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis))*100, digits = 1)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
#min-max normalization function
normalize <- function(x){
return ((x - min(x)) / (max(x) - min(x)))
}
#Normalizations using min-max and Z-scores (omit 1st column i.e. "ID")
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
wbcd_z <- as.data.frame(scale(wbcd[-1]))
#confirm normalization is working as intended
summary(wbcd_z$area_mean)
#segmentation of dataset into Training & Test data (for both n and z norms)
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]
wbcd_train_z <- wbcd_z[1:469, ]
wbcd_test_z <- wbcd_z[470:569, ]
#extraction of true labels for training and test results
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]
#run the KNN algo with k = 21 (sqrt(469)) with normalized data
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k = 21)
#run the KNN algo with k = 21 (sqrt(469)) with z-normalized data
wbcd_test_pred_z <- knn(train = wbcd_train_z, test = wbcd_test_z, cl = wbcd_train_labels, k = 21)
#compare results for both n and z normalized data
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq = FALSE)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred_z, prop.chisq = FALSE)
sqrt(48^2 + 20^2)
for(i in 1:20){}
for(i in 1:20){
print(i)
}
sms_raw <- read.csv(url("https://raw.githubusercontent.com/dataspelunking/MLwR/master/Machine%20Learning%20with%20R%20(2nd%20Ed.)/Chapter%2004/sms_spam.csv"))
str(sms_raw)
sms_raw <- read.csv(url("https://raw.githubusercontent.com/dataspelunking/
MLwR/master/Machine%20Learning%20with%20R%20(2nd%20Ed.)/
Chapter%2004/sms_spam.csv"), stringAsFactors = FALSE)
sms_raw <- read.csv(url("https://raw.githubusercontent.com/dataspelunking/MLwR/master/Machine%20Learning%20with%20R%20(2nd%20Ed.)/Chapter%2004/sms_spam.csv"), stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type <- factor(sms_raw$type)
str(sms_raw)
str(sms_raw)
table(sms_raw$type)
install.packages("tm")
library(tm)
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("NLP")
install.packages("NLP")
install.packages("tm")
library(tm)
install.packages("slam")
install.packages('devtools')
library(devtools)
slam_url <- "https://cran.r-project.org/src/contrib/Archive/slam/slam_0.1-37.tar.gz"
install_url(slam_url)
session_info()
updateR()
if(!require(installr)) {
install.packages("installr");
require(installr)
}
updateR()
sessionInfo()
install.packages("tm")
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:3], as.character)
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
lapply(sms_corpus_clean[1:3], as.character)
getTransformations()
?stopwords
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords())
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)
install.packages("SnowballC")
library(SnowballC)
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
lapply(sms_corpus_clean[1:3], as.character)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace)
lapply(sms_corpus_clean[1:3], as.character)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
print(sms_dtm)
print(sms_dtm[1:3])
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test <- sms_dtm[4169:5559, ]
# create training and tests labels (from raw corpus)
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels <- sms_raw[4169:5559, ]$type
# compare proportion of ham vs spam in both sets
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE, random.color = TRUE)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE, random.color = FALSE)
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
spam <- subset(sms_raw, type == "spam")
ham <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test <- sms_dtm[4169:5559, ]
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels <- sms_raw[4169:5559, ]$type
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)
# import data
sms_raw <- read.csv(url("https://raw.githubusercontent.com/dataspelunking/MLwR/master/Machine%20Learning%20with%20R%20(2nd%20Ed.)/Chapter%2004/sms_spam.csv"), stringsAsFactors = FALSE)
# turn categorical 'type' variable into factor
sms_raw$type <- factor(sms_raw$type)
# get info on imported data
str(sms_raw)
table(sms_raw$type)
# create corpus of SMS messages
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
# check 1st element of corpus
as.character(sms_corpus[[1]])
# check a list of corpus elements
lapply(sms_corpus[1:3], as.character)
#------------begin cleaning corpus---------------------
# apply lower case transformation to corpus, and check...
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
lapply(sms_corpus_clean[1:3], as.character)
# remove numbers from corpus
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)
# remove stop words from corpus (to, and, but, ...)
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords())
# remove punctuation from corpus
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)
# stem corpus ( learned, learning, learns -> learn)
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
# strip whitespace
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace)
#--------------corpus cleaning finalized---------------------
# create a "Document Term Matrix" (DTM). Creates matrix word count per document (SMS).
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
# create training and tests sets
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test <- sms_dtm[4169:5559, ]
# create training and tests labels (from raw corpus)
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels <- sms_raw[4169:5559, ]$type
# compare proportion of ham vs spam in both sets
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
#create wordcloud to visulaize frequency of words
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE, random.color = FALSE)
# create and compare wordclouds for ham vs spam (wordcloud applies text prep. processes automatically)
spam <- subset(sms_raw, type == "spam")
ham <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
# create a vector with the most frequent words (appearing at least five times)
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
1/(1+.05)^-.25
1/(1+.05)^.25
exp(-.05*.25)
250*1.5
375000-361750
1.5-1.4410
.059*250000
# Survival on the Titanic
# Load Data (links expire - must sign into kaggle and copy new links)
titanic_train <- read.csv(url("https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/train.csv?GoogleAccessId=competitions-data@kaggle-161607.iam.gserviceaccount.com&Expires=1503149409&Signature=n7NVB%2Be2TMDsY9E9aygUxvAjyT6tTeP4nXfbZicZ8BDfXajpqi7937layk7%2Fi%2Bg%2Bq6dyDr%2BRbLuIN%2BtcK%2Br%2FrGHibYtrLHwfcfJAKoApD0HJCjbaJpaIs2AUEKU%2FL4qExeYVLcjFDHWkic1PBz62AfhRyT9RdTQ4VuyRkyvbDRhMWHMApvMUtam9F9fdvDrQwjvBzS7MFEYTBqT6%2BcKxcWtGMNO6t%2BrbwzzMyMNMPcdcbk0C%2BKEj7unRreO%2BQjSIyzLhxc47csT%2FuqfGz8qoxTyBfF3lpDuhfJUqVT1B56aUQZSViWTTSAGDu5KUEokkSuY0K8gCYa9e0abiThxjsg%3D%3D"), stringsAsFactors = FALSE)
#write.csv(titanic_train, file = "titanic_train.csv")
titanic_test <- read.csv(url("https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv?GoogleAccessId=competitions-data@kaggle-161607.iam.gserviceaccount.com&Expires=1503149443&Signature=RCoWifzKTM5X7enJq9b0QccLq2ls8SlHRSYks7PgBXQ3Lrw3myskMGU3IsyhUbc6JnBxP%2FcDH5X6ohKOEujDMIpXxA5Pea5Kr6hSD%2FOvxEsbaKNIzTtVX3lWH0cBW0LpxtqqB%2FqA%2FcBJnwz39gOREhKFMXFD3vRVSlaPlmp6Ct4EEoGTUV1K7idWd7XEAUiNan9lIpHvqmQwOisKwRRBy4h69t9ef334mC47cUHDfz8RpfIK6htzpP0FKjynHa9ZE%2FT92hGGOWU0M6RfAJQvWNq02Vvh3KhUpPzmmAI5qk4%2B7dbr0qFY5ZIzzCTu6LWJga1zuDp1RgHzt3Cbz2sIMA%3D%3D"), stringsAsFactors = FALSE)
#write.csv(titanic_test, file = "titanic_test.csv")
#titanic_train <- read.csv("titanic_train.csv")
#titanic_test <- read.csv("titanic_test.csv")
# Inspect data
str(titanic_test)
table(titanic_train$Sex)
# -------- Prepare data for cleaning. CLEAN it -------------
# Add Column to each data set. Column of TRUE if train set, FALSE is test set.
titanic_train$isTrainSet <- TRUE
titanic_test$isTrainSet <- FALSE
# check to make sure all "TrainSet" data points returnTRUE
tail(titanic_train$isTrainSet)
# Add "Survived" column to "test" dataset in order to match it with "train" set.
titanic_test$Survived <- NA
names(titanic_test)
# Bind both datasets into singe one (for cleaning purposes)
titanic_full <- rbind(titanic_train, titanic_test)
# Query "embarked" column to find any missing values. Replace missing values with the node.
table(titanic_full$Embarked) # Node = "S"
titanic_full[titanic_full$Embarked == "", "Embarked"] <- "S"
# Query Age column to see of there are any missing values.
table(is.na(titanic_full$Age))
boxplot(titanic_full$Age)
boxplot.stats(titanic_full$Age)
# Obtain max age from stats and use it to filter outliers.
maxAge <- boxplot.stats(titanic_full$Age)$stats[5]
age_filter <- titanic_full$Age < maxAge # creates rule
titanic_full[age_filter,] # applies rule to data
# Use regression to predict unknown "age" values.
age_eqn = "Age ~ Pclass + Sex + SibSp + Parch + Embarked" # i.e. predict age given Pclass, Sex,...
age_model <- lm(
formula = age_eqn,
data = titanic_full[age_filter,] # supply linear regression method with clean 'age' data (no outliers).
)
# Predict values
age_row <- titanic_full[is.na(titanic_full$Age), c("Pclass", "Sex", "Embarked", "SibSp", "Parch")]
# above: only query rows that have missing values in "age". Only want to see "Pclass", "Sex", ... Save.
age_predictions <- predict(age_model, newdata = age_row) # predict using "age_model", on age_row.
# Replace missing values with predicted values.
titanic_full[is.na(titanic_full$Age), "Age"] <- age_predictions
#age_median <- median(titanic_full$Age, na.rm = TRUE) # calculate median (remove missing values from calc.)
#titanic_full[is.na(titanic_full$Age), "Age"] <- age_median
# Query "Fare" column to see of there are any missing values. Replace with median.
table(is.na(titanic_full$Fare))
boxplot(titanic_full$Fare)
boxplot.stats(titanic_full$Fare) # returns median 1st Q, 3rd Q, etc.
# Obtain max fare from stats and use it to filter outliers.
maxFare <- boxplot.stats(titanic_full$Fare)$stats[5]
fare_filter <- titanic_full$Fare < maxFare # creates rule
titanic_full[fare_filter,] # applies rule to data
# Use regression to predict unknown "fare" values.
fare_eqn = "Fare ~ Pclass + Sex + SibSp + Parch + Embarked" # i.e. predict fare given Pclass, Sex,...
fare_model <- lm(
formula = fare_eqn,
data = titanic_full[fare_filter,] # supply linear regression method with clean fare data (no outliers).
)
# Predict values
fare_row <- titanic_full[is.na(titanic_full$Fare), c("Pclass", "Sex", "Embarked", "SibSp", "Parch")]
# above: only query rows that have missing values in "fare". Only want to see "Pclass", "Sex", ... Save.
fare_predictions <- predict(fare_model, newdata = fare_row) # predict using "fare_model", on fare_row.
# Replace missing values with predicted values.
titanic_full[is.na(titanic_full$Fare), "Fare"] <- fare_predictions
#fare_median <- median(titanic_full$Fare, na.rm = TRUE) # calculate median (remove missing values from calc.)
#titanic_full[is.na(titanic_full$Fare), "Fare"] <- fare_median
# Categorical casting
titanic_full$Pclass <- factor(titanic_full$Pclass, levels=c(3,2,1),ordered=TRUE)
titanic_full$Pclass <- as.factor(titanic_full$Pclass)
titanic_full$Sex <- as.factor(titanic_full$Sex)
titanic_full$Embarked <- as.factor(titanic_full$Embarked)
# Re-split data into train and test set
titanic_train <- titanic_full[titanic_full$isTrainSet==TRUE,]
titanic_test <- titanic_full[titanic_full$isTrainSet==FALSE,]
# Cast "Survived" column in training set as categorical.
titanic_train$Survived <- as.factor(titanic_train$Survived)
# ---------------------------------------------------------
# Remove unnecessary & unique variables
titanic_train <- titanic_train[c(-1, -4, -9, -10, -11, -12, -13)]
titanic_test <- titanic_test[c(-1, -2, -4, -9, -10, -11, -12, -13)]
# Train model
titanic_model <- C5.0(titanic_train[-1], as.factor(titanic_train$Survived))
summary(titanic_model)
# Make prediction
titanic_pred <- predict(titanic_model, titanic_test)
# Obtain proportions
prop.table(table(titanic_test$Sex))
prop.table(table(titanic_pred))
# Save as .CSV and prep data for submission to Kaggle.
titanic_pred <- as.data.frame(titanic_pred)
write.csv(titanic_pred, file = "titanicPrediction.csv")
#--------------------------------------------------------------------
# Implement "boosting" algorithms to improve model. (See: AdaBoost).
#--------------------------------------------------------------------
# below: learn to predict "Survived" based on all of the categories found in data = titanic_train"
AdaB_model <- boosting(Survived ~ ., data = titanic_train, boos = TRUE)
predict_AdaB <- predict(AdaB_model, titanic_test)
str(predict_AdaB)
# Prep to save as CSV
colHeadings <- c("PassengerId", "Survived")
AdaB_predDataframe <- data.frame(c(892:1309), c(predict_AdaB$class))
names(AdaB_predDataframe) <- colHeadings
write.csv(AdaB_predDataframe, file = "AdaB_TitanicPred.csv", row.names = FALSE)
library("C50", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# Survival on the Titanic
# Load Data (links expire - must sign into kaggle and copy new links)
titanic_train <- read.csv(url("https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/train.csv?GoogleAccessId=competitions-data@kaggle-161607.iam.gserviceaccount.com&Expires=1503149409&Signature=n7NVB%2Be2TMDsY9E9aygUxvAjyT6tTeP4nXfbZicZ8BDfXajpqi7937layk7%2Fi%2Bg%2Bq6dyDr%2BRbLuIN%2BtcK%2Br%2FrGHibYtrLHwfcfJAKoApD0HJCjbaJpaIs2AUEKU%2FL4qExeYVLcjFDHWkic1PBz62AfhRyT9RdTQ4VuyRkyvbDRhMWHMApvMUtam9F9fdvDrQwjvBzS7MFEYTBqT6%2BcKxcWtGMNO6t%2BrbwzzMyMNMPcdcbk0C%2BKEj7unRreO%2BQjSIyzLhxc47csT%2FuqfGz8qoxTyBfF3lpDuhfJUqVT1B56aUQZSViWTTSAGDu5KUEokkSuY0K8gCYa9e0abiThxjsg%3D%3D"), stringsAsFactors = FALSE)
#write.csv(titanic_train, file = "titanic_train.csv")
titanic_test <- read.csv(url("https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv?GoogleAccessId=competitions-data@kaggle-161607.iam.gserviceaccount.com&Expires=1503149443&Signature=RCoWifzKTM5X7enJq9b0QccLq2ls8SlHRSYks7PgBXQ3Lrw3myskMGU3IsyhUbc6JnBxP%2FcDH5X6ohKOEujDMIpXxA5Pea5Kr6hSD%2FOvxEsbaKNIzTtVX3lWH0cBW0LpxtqqB%2FqA%2FcBJnwz39gOREhKFMXFD3vRVSlaPlmp6Ct4EEoGTUV1K7idWd7XEAUiNan9lIpHvqmQwOisKwRRBy4h69t9ef334mC47cUHDfz8RpfIK6htzpP0FKjynHa9ZE%2FT92hGGOWU0M6RfAJQvWNq02Vvh3KhUpPzmmAI5qk4%2B7dbr0qFY5ZIzzCTu6LWJga1zuDp1RgHzt3Cbz2sIMA%3D%3D"), stringsAsFactors = FALSE)
#write.csv(titanic_test, file = "titanic_test.csv")
#titanic_train <- read.csv("titanic_train.csv")
#titanic_test <- read.csv("titanic_test.csv")
# Inspect data
str(titanic_test)
table(titanic_train$Sex)
# -------- Prepare data for cleaning. CLEAN it -------------
# Add Column to each data set. Column of TRUE if train set, FALSE is test set.
titanic_train$isTrainSet <- TRUE
titanic_test$isTrainSet <- FALSE
# check to make sure all "TrainSet" data points returnTRUE
tail(titanic_train$isTrainSet)
# Add "Survived" column to "test" dataset in order to match it with "train" set.
titanic_test$Survived <- NA
names(titanic_test)
# Bind both datasets into singe one (for cleaning purposes)
titanic_full <- rbind(titanic_train, titanic_test)
# Query "embarked" column to find any missing values. Replace missing values with the node.
table(titanic_full$Embarked) # Node = "S"
titanic_full[titanic_full$Embarked == "", "Embarked"] <- "S"
# Query Age column to see of there are any missing values.
table(is.na(titanic_full$Age))
boxplot(titanic_full$Age)
boxplot.stats(titanic_full$Age)
# Obtain max age from stats and use it to filter outliers.
maxAge <- boxplot.stats(titanic_full$Age)$stats[5]
age_filter <- titanic_full$Age < maxAge # creates rule
titanic_full[age_filter,] # applies rule to data
# Use regression to predict unknown "age" values.
age_eqn = "Age ~ Pclass + Sex + SibSp + Parch + Embarked" # i.e. predict age given Pclass, Sex,...
age_model <- lm(
formula = age_eqn,
data = titanic_full[age_filter,] # supply linear regression method with clean 'age' data (no outliers).
)
# Predict values
age_row <- titanic_full[is.na(titanic_full$Age), c("Pclass", "Sex", "Embarked", "SibSp", "Parch")]
# above: only query rows that have missing values in "age". Only want to see "Pclass", "Sex", ... Save.
age_predictions <- predict(age_model, newdata = age_row) # predict using "age_model", on age_row.
# Replace missing values with predicted values.
titanic_full[is.na(titanic_full$Age), "Age"] <- age_predictions
#age_median <- median(titanic_full$Age, na.rm = TRUE) # calculate median (remove missing values from calc.)
#titanic_full[is.na(titanic_full$Age), "Age"] <- age_median
# Query "Fare" column to see of there are any missing values. Replace with median.
table(is.na(titanic_full$Fare))
boxplot(titanic_full$Fare)
boxplot.stats(titanic_full$Fare) # returns median 1st Q, 3rd Q, etc.
# Obtain max fare from stats and use it to filter outliers.
maxFare <- boxplot.stats(titanic_full$Fare)$stats[5]
fare_filter <- titanic_full$Fare < maxFare # creates rule
titanic_full[fare_filter,] # applies rule to data
# Use regression to predict unknown "fare" values.
fare_eqn = "Fare ~ Pclass + Sex + SibSp + Parch + Embarked" # i.e. predict fare given Pclass, Sex,...
fare_model <- lm(
formula = fare_eqn,
data = titanic_full[fare_filter,] # supply linear regression method with clean fare data (no outliers).
)
# Predict values
fare_row <- titanic_full[is.na(titanic_full$Fare), c("Pclass", "Sex", "Embarked", "SibSp", "Parch")]
# above: only query rows that have missing values in "fare". Only want to see "Pclass", "Sex", ... Save.
fare_predictions <- predict(fare_model, newdata = fare_row) # predict using "fare_model", on fare_row.
# Replace missing values with predicted values.
titanic_full[is.na(titanic_full$Fare), "Fare"] <- fare_predictions
#fare_median <- median(titanic_full$Fare, na.rm = TRUE) # calculate median (remove missing values from calc.)
#titanic_full[is.na(titanic_full$Fare), "Fare"] <- fare_median
# Categorical casting
titanic_full$Pclass <- factor(titanic_full$Pclass, levels=c(3,2,1),ordered=TRUE)
titanic_full$Pclass <- as.factor(titanic_full$Pclass)
titanic_full$Sex <- as.factor(titanic_full$Sex)
titanic_full$Embarked <- as.factor(titanic_full$Embarked)
# Re-split data into train and test set
titanic_train <- titanic_full[titanic_full$isTrainSet==TRUE,]
titanic_test <- titanic_full[titanic_full$isTrainSet==FALSE,]
# Cast "Survived" column in training set as categorical.
titanic_train$Survived <- as.factor(titanic_train$Survived)
# ---------------------------------------------------------
# Remove unnecessary & unique variables
titanic_train <- titanic_train[c(-1, -4, -9, -10, -11, -12, -13)]
titanic_test <- titanic_test[c(-1, -2, -4, -9, -10, -11, -12, -13)]
# Train model
titanic_model <- C5.0(titanic_train[-1], as.factor(titanic_train$Survived))
summary(titanic_model)
# Make prediction
titanic_pred <- predict(titanic_model, titanic_test)
# Obtain proportions
prop.table(table(titanic_test$Sex))
prop.table(table(titanic_pred))
# Save as .CSV and prep data for submission to Kaggle.
titanic_pred <- as.data.frame(titanic_pred)
write.csv(titanic_pred, file = "titanicPrediction.csv")
#--------------------------------------------------------------------
# Implement "boosting" algorithms to improve model. (See: AdaBoost).
#--------------------------------------------------------------------
# below: learn to predict "Survived" based on all of the categories found in data = titanic_train"
AdaB_model <- boosting(Survived ~ ., data = titanic_train, boos = TRUE)
predict_AdaB <- predict(AdaB_model, titanic_test)
str(predict_AdaB)
# Prep to save as CSV
colHeadings <- c("PassengerId", "Survived")
AdaB_predDataframe <- data.frame(c(892:1309), c(predict_AdaB$class))
names(AdaB_predDataframe) <- colHeadings
write.csv(AdaB_predDataframe, file = "AdaB_TitanicPred.csv", row.names = FALSE)
library("adabag", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# Survival on the Titanic
# Load Data (links expire - must sign into kaggle and copy new links)
titanic_train <- read.csv(url("https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/train.csv?GoogleAccessId=competitions-data@kaggle-161607.iam.gserviceaccount.com&Expires=1503149409&Signature=n7NVB%2Be2TMDsY9E9aygUxvAjyT6tTeP4nXfbZicZ8BDfXajpqi7937layk7%2Fi%2Bg%2Bq6dyDr%2BRbLuIN%2BtcK%2Br%2FrGHibYtrLHwfcfJAKoApD0HJCjbaJpaIs2AUEKU%2FL4qExeYVLcjFDHWkic1PBz62AfhRyT9RdTQ4VuyRkyvbDRhMWHMApvMUtam9F9fdvDrQwjvBzS7MFEYTBqT6%2BcKxcWtGMNO6t%2BrbwzzMyMNMPcdcbk0C%2BKEj7unRreO%2BQjSIyzLhxc47csT%2FuqfGz8qoxTyBfF3lpDuhfJUqVT1B56aUQZSViWTTSAGDu5KUEokkSuY0K8gCYa9e0abiThxjsg%3D%3D"), stringsAsFactors = FALSE)
#write.csv(titanic_train, file = "titanic_train.csv")
titanic_test <- read.csv(url("https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv?GoogleAccessId=competitions-data@kaggle-161607.iam.gserviceaccount.com&Expires=1503149443&Signature=RCoWifzKTM5X7enJq9b0QccLq2ls8SlHRSYks7PgBXQ3Lrw3myskMGU3IsyhUbc6JnBxP%2FcDH5X6ohKOEujDMIpXxA5Pea5Kr6hSD%2FOvxEsbaKNIzTtVX3lWH0cBW0LpxtqqB%2FqA%2FcBJnwz39gOREhKFMXFD3vRVSlaPlmp6Ct4EEoGTUV1K7idWd7XEAUiNan9lIpHvqmQwOisKwRRBy4h69t9ef334mC47cUHDfz8RpfIK6htzpP0FKjynHa9ZE%2FT92hGGOWU0M6RfAJQvWNq02Vvh3KhUpPzmmAI5qk4%2B7dbr0qFY5ZIzzCTu6LWJga1zuDp1RgHzt3Cbz2sIMA%3D%3D"), stringsAsFactors = FALSE)
#write.csv(titanic_test, file = "titanic_test.csv")
#titanic_train <- read.csv("titanic_train.csv")
#titanic_test <- read.csv("titanic_test.csv")
# Inspect data
str(titanic_test)
table(titanic_train$Sex)
# -------- Prepare data for cleaning. CLEAN it -------------
# Add Column to each data set. Column of TRUE if train set, FALSE is test set.
titanic_train$isTrainSet <- TRUE
titanic_test$isTrainSet <- FALSE
# check to make sure all "TrainSet" data points returnTRUE
tail(titanic_train$isTrainSet)
# Add "Survived" column to "test" dataset in order to match it with "train" set.
titanic_test$Survived <- NA
names(titanic_test)
# Bind both datasets into singe one (for cleaning purposes)
titanic_full <- rbind(titanic_train, titanic_test)
# Query "embarked" column to find any missing values. Replace missing values with the node.
table(titanic_full$Embarked) # Node = "S"
titanic_full[titanic_full$Embarked == "", "Embarked"] <- "S"
# Query Age column to see of there are any missing values.
table(is.na(titanic_full$Age))
boxplot(titanic_full$Age)
boxplot.stats(titanic_full$Age)
# Obtain max age from stats and use it to filter outliers.
maxAge <- boxplot.stats(titanic_full$Age)$stats[5]
age_filter <- titanic_full$Age < maxAge # creates rule
titanic_full[age_filter,] # applies rule to data
# Use regression to predict unknown "age" values.
age_eqn = "Age ~ Pclass + Sex + SibSp + Parch + Embarked" # i.e. predict age given Pclass, Sex,...
age_model <- lm(
formula = age_eqn,
data = titanic_full[age_filter,] # supply linear regression method with clean 'age' data (no outliers).
)
# Predict values
age_row <- titanic_full[is.na(titanic_full$Age), c("Pclass", "Sex", "Embarked", "SibSp", "Parch")]
# above: only query rows that have missing values in "age". Only want to see "Pclass", "Sex", ... Save.
age_predictions <- predict(age_model, newdata = age_row) # predict using "age_model", on age_row.
# Replace missing values with predicted values.
titanic_full[is.na(titanic_full$Age), "Age"] <- age_predictions
#age_median <- median(titanic_full$Age, na.rm = TRUE) # calculate median (remove missing values from calc.)
#titanic_full[is.na(titanic_full$Age), "Age"] <- age_median
# Query "Fare" column to see of there are any missing values. Replace with median.
table(is.na(titanic_full$Fare))
boxplot(titanic_full$Fare)
boxplot.stats(titanic_full$Fare) # returns median 1st Q, 3rd Q, etc.
# Obtain max fare from stats and use it to filter outliers.
maxFare <- boxplot.stats(titanic_full$Fare)$stats[5]
fare_filter <- titanic_full$Fare < maxFare # creates rule
titanic_full[fare_filter,] # applies rule to data
# Use regression to predict unknown "fare" values.
fare_eqn = "Fare ~ Pclass + Sex + SibSp + Parch + Embarked" # i.e. predict fare given Pclass, Sex,...
fare_model <- lm(
formula = fare_eqn,
data = titanic_full[fare_filter,] # supply linear regression method with clean fare data (no outliers).
)
# Predict values
fare_row <- titanic_full[is.na(titanic_full$Fare), c("Pclass", "Sex", "Embarked", "SibSp", "Parch")]
# above: only query rows that have missing values in "fare". Only want to see "Pclass", "Sex", ... Save.
fare_predictions <- predict(fare_model, newdata = fare_row) # predict using "fare_model", on fare_row.
# Replace missing values with predicted values.
titanic_full[is.na(titanic_full$Fare), "Fare"] <- fare_predictions
#fare_median <- median(titanic_full$Fare, na.rm = TRUE) # calculate median (remove missing values from calc.)
#titanic_full[is.na(titanic_full$Fare), "Fare"] <- fare_median
# Categorical casting
titanic_full$Pclass <- factor(titanic_full$Pclass, levels=c(3,2,1),ordered=TRUE)
titanic_full$Pclass <- as.factor(titanic_full$Pclass)
titanic_full$Sex <- as.factor(titanic_full$Sex)
titanic_full$Embarked <- as.factor(titanic_full$Embarked)
# Re-split data into train and test set
titanic_train <- titanic_full[titanic_full$isTrainSet==TRUE,]
titanic_test <- titanic_full[titanic_full$isTrainSet==FALSE,]
# Cast "Survived" column in training set as categorical.
titanic_train$Survived <- as.factor(titanic_train$Survived)
# ---------------------------------------------------------
# Remove unnecessary & unique variables
titanic_train <- titanic_train[c(-1, -4, -9, -10, -11, -12, -13)]
titanic_test <- titanic_test[c(-1, -2, -4, -9, -10, -11, -12, -13)]
# Train model
titanic_model <- C5.0(titanic_train[-1], as.factor(titanic_train$Survived))
summary(titanic_model)
# Make prediction
titanic_pred <- predict(titanic_model, titanic_test)
# Obtain proportions
prop.table(table(titanic_test$Sex))
prop.table(table(titanic_pred))
# Save as .CSV and prep data for submission to Kaggle.
titanic_pred <- as.data.frame(titanic_pred)
write.csv(titanic_pred, file = "titanicPrediction.csv")
#--------------------------------------------------------------------
# Implement "boosting" algorithms to improve model. (See: AdaBoost).
#--------------------------------------------------------------------
# below: learn to predict "Survived" based on all of the categories found in data = titanic_train"
AdaB_model <- boosting(Survived ~ ., data = titanic_train, boos = TRUE)
predict_AdaB <- predict(AdaB_model, titanic_test)
str(predict_AdaB)
# Prep to save as CSV
colHeadings <- c("PassengerId", "Survived")
AdaB_predDataframe <- data.frame(c(892:1309), c(predict_AdaB$class))
names(AdaB_predDataframe) <- colHeadings
write.csv(AdaB_predDataframe, file = "AdaB_TitanicPred.csv", row.names = FALSE)
setwd("~/Desktop/Machine-Learning/DecisionTrees")
View(titanic_train)
